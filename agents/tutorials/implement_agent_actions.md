---
permalink: /agents/tutorials/implement_agent_actions
title: Agent Actions communication with MFE
layout: default
section_title: Agents
---

## Introduction

In order to communicate between Copilot in SidePanel and any MFE, we introduced [Agent Actions](../concepts.md#actions) which communicate with MFEs via Integration Events. For this approach, the definition of `manifest.yaml` is required.

### Use case

Through the conversation in SidePanel we would like to make changes in MFE. As an example, in Sidepanel user asks `Please change duration of task X to 5 days`, and Copilot via Scheduler Agent apply this changes to Scheduler MFE.

Under the hood this use case could be implemented via [non-interactive Action](../concepts.md#non-interactive-actions) and handing Agent Actions in MFE.

## How to implement

### 1. Define Agent Actions in manifest

Extend Agent definition with `actions` section, for more details please check [Manifest Schema](../schema.md)

Actions are declared at the manifest file level of a specific agent by filling in the "actions" field. Letâ€™s add a simple RFI draft agent whose goal is to return a subject and a detailed question based on the user's request, and we will include actions in its structure.

```yaml
name: examples  
name_for_human: Examples
metadata: { }

agents:  
- name: rfi_drafter
  enable_in_conversation: false  
  type: prompt  
  description: Drafts RFI fields based on input question
  prompt: |
      Given user's input {question}, generate question and subject for new RFI

      {action_prompt}
  actions:
  - include_when: If the question and subject are generated successfully  # Instructions to LLM when to include this action in output and therefore in UI
    # Payload for the action
    action:
      title: Apply to RFI
      id: apply_to_rfi
      tooltip: Apply values to RFI 
      disabled_tooltip: This functionality only applies when you're in Create a New RFI page. 
      icon: apply.svg
      type: action
      supported_urls: ['tools/rfis/create']
      # integration_event indicates that action should trigger Integration Event
      integration_event:
        data: # Payload for event, that would be sent to MFE
          subject: guessed subject
          question: guessed question
        metadata:
          type: copilot:apply_to_rfi

  input_schema:
    title: Input schema  
    description: Input schema for RFI Drafter agent  
    type: object  
    properties:  
    question:
      type: string
      description: Question provided by user
  # actions schema would added to output schema automatically  
  output_schema:  
    title: Output schema  
    description: Output schema for RFI Drafter agent
    type: object  
    properties:  
      subject:
        type: string  
        description: Short, descriptive summary of user input question 
      question:
        type: string  
        description: Original question, with fixed grammar and spelling  
      actions:
        type: list
        description: Generated actions that strictly correspond to actions schema in prompt
```

Here is the brief overview of actions structure:
- **title[str]**: The name of the action or the content of the button (if it is an interactive action).
- **id[str]**: The unique ID of the action, which would be used by integrations to implement functionality.
- **tooltip[Optional[str]]**: A human-readable description; clients might decide to render it as a tooltip when the button is active.
- **disabled_tooltip[Optional[str]]**: A human-readable description; clients might decide to render it as a tooltip when the button is disabled.
- **type[str]**: Could be "action" or "non_interactive." *By default, it is "action"*.
- **icon[Optional[str]]**: The icon to be rendered by the client.
- **supported_urls[Optional[list[str]]]**: Webpage URL patterns where the interactive action (button) should be active.
- **integration_event[dict[Literal["data", "metadata"]], Any]**: Indicator and config that action should trigger Integration Event. In the data field we pass what we would like to generate. Here, for example, we want to return guessed subject and question

In addition to adding actions as a separate field, we also need to include actions in the `output_schema` and add an `action_prompt` placeholder in the prompt. Under the hood, this placeholder allows the LLM to analyze the conditions specified in `include_when` for executing actions and make the appropriate decision. If the condition is met, we should see the generated actions contains guessed subject and question generated by LLM in integration_event field. If your prompt is not compact enough and includes many instructions for content generation, you can specify an additional message in your prompt instructions like 

```yaml
prompt: 
<<Instructions_section>>
1. First instruction
2. Second instruction
*
*
10. Use the 'Actions' section to generate actions.
```

### 2. Implement Action handling in MFE

In MFE app add next changes

```javascript
  import {
    IntegrationEvents,
    IntegrationEventNames,
    ProcoreEventDetail,
  } from '@procore/web-sdk-events';

  const integrationEvents = new IntegrationEvents('mfeServiceName');

  const Component = () => {
    // The listener should be placed inside a useEffect to ensure it is unsubscribed when the component unmounts
    React.useEffect(() => {
      const listener = (event: ProcoreEventDetail) => {
      // The type value should be unique
        if (event.type === 'copilot:apply_to_rfi') {
          try {
            // The logic for applying changes from event.data should be placed here

            // As a way of providing feedback
            showToast.success('success');
          } catch (e) {
            showToast.error('error');
          }
        }
      };

      const unsubscribe = integrationEvents.subscribe(
        IntegrationEventNames.ACTION_REQUESTED,
        listener
      );

      return () => unsubscribe();
    }, []);

    return <></>;
  };
```

## How it works

### Agent Actions

After defining Actions in Agent, we should be able to receive them from the Conversation API as an answer in Copilot Sidepanel. Based on the Action type, the logic for `action` or `non_interactive` types on the UI differs: `action` will be rendered as a button, while `non_interactive` will be invoked immediately and not rendered. Additionally, Action is expected to have `integration_event` with `data` and `metadata` included to enable calling Integration Event.

You can find Copilot Actions React Component [here](https://github.com/procore/copilot/blob/main/ui/src/components/Message/subcomponents/CopilotActions.tsx) and Action UI Interface [here](https://github.com/procore/copilot/blob/main/ui/src/shared/types.d.ts#L24)

### Integration Events

As a way of communication, we are using [Integration Events](https://github.com/procore/web-sdk/tree/main/packages/events) with specific name [ACTION_REQUESTED](https://github.com/procore/web-sdk/blob/main/packages/events/src/constants.ts#L65)

When the user invokes Integration Event via a button click, method `publish` is called.

```javascript
  // Publish is invoked only when `integration_event` is provided
  if (action.integration_event) {
    integrationEvents.publish(
      IntegrationEventNames.ACTION_REQUESTED,
      action.integration_event.data,
      // This is a required field, as events on the MFE side will be filtered based on the value of this property
      { type: action.integration_event.metadata?.type }
    );
  }
```
